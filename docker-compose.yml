services:
  # Services existants (extensions du docker-compose.yml de vexa)
  api-gateway:
    extends:
      file: ./vexa/docker-compose.yml
      service: api-gateway
    networks:
      - vexa_default
      - vexa_network

  bot-manager:
    extends:
      file: ./vexa/docker-compose.yml
      service: bot-manager
    environment:
      - BOT_LOGS_HOST_DIR=/Users/thibaud/Documents/development/gladia-meet-project/gladia-meet-bot/persistent_data/logs
      - BOT_SCREENSHOTS_HOST_DIR=/Users/thibaud/Documents/development/gladia-meet-project/gladia-meet-bot/persistent_data/screenshots
      - BOT_ENABLE_SCREENSHOTS=${BOT_ENABLE_SCREENSHOTS:-false}
      - GLADIA_API_URL=http://gladia-proxy:8084
    volumes:
      - ./persistent_data:/opt/vexa-bot/persistent_data
    networks:
      - vexa_default
      - vexa_network

  admin-api:
    extends:
      file: ./vexa/docker-compose.yml
      service: admin-api
    networks:
      - vexa_default
      - vexa_network

  redis:
    extends:
      file: ./vexa/docker-compose.yml
      service: redis
    networks:
      - vexa_default
      - vexa_network

  postgres:
    extends:
      file: ./vexa/docker-compose.yml
      service: postgres
    networks:
      - vexa_default
      - vexa_network

  traefik:
    extends:
      file: ./vexa/docker-compose.yml
      service: traefik
    networks:
      - vexa_default
      - vexa_network

  # Nouveaux services dockeris√©s
  bot-launcher:
    build: ./services/bot-launcher/
    ports:
      - "8081:8080"
    environment:
      - API_GATEWAY_URL=http://api-gateway:8000
      - API_KEY=${API_KEY}
    depends_on:
      - api-gateway
    networks:
      - vexa_network
      - vexa_default
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.bot-launcher.rule=Host(`bot-launcher.localhost`)"
      - "traefik.http.services.bot-launcher.loadbalancer.server.port=8080"

  log-monitor:
    build: ./services/log-monitor/
    ports:
      - "8082:8080"
    environment:
      - API_KEY=${API_KEY}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - vexa_network
      - vexa_default
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.log-monitor.rule=Host(`log-monitor.localhost`)"
      - "traefik.http.services.log-monitor.loadbalancer.server.port=8080"

  transcript-retriever:
    build: ./services/transcript-retriever/
    ports:
      - "8083:8080"
    environment:
      - API_GATEWAY_URL=http://api-gateway:8000
      - API_KEY=${API_KEY}
      - GLADIA_API_KEY=${GLADIA_API_KEY}
    depends_on:
      - api-gateway
    networks:
      - vexa_network
      - vexa_default
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.transcript-retriever.rule=Host(`transcript-retriever.localhost`)"
      - "traefik.http.services.transcript-retriever.loadbalancer.server.port=8080"

  whisper-backend:
    build:
      context: ./services/whisper-backend
      dockerfile: Dockerfile
    environment:
      - WHISPER_MODEL_SIZE=medium
      # "medium" ~1.5GB VRAM/RAM, "large-v3" ~3GB. User has 4GB total RAM (3.1 available).
      # "medium" is safer. "distil-large-v3" is also an option if supported by faster-whisper version.
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    volumes:
      - ./whisper-cache:/root/.cache/huggingface # Persist model downloads
    restart: unless-stopped
    depends_on:
      - redis
    networks:
      - vexa_network
      - vexa_default

  gladia-proxy:
    build:
      context: ./services/gladia-murmure-proxy
      dockerfile: Dockerfile
    ports:
      - "8084:8084"
    environment:
      - PORT=8084
      - WHISPER_API_URL=http://whisper-backend:5000
      - PROXY_PUBLIC_HOST=gladia-proxy:8084
    depends_on:
      - whisper-backend
    networks:
      - vexa_network
      - vexa_default

volumes:
  redis-data:
  postgres-data:

networks:
  vexa_network:
    driver: bridge
  vexa_default:
    driver: bridge
